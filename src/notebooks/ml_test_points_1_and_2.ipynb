{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prueba ML Engineer - Juan Sebastian Rojas Melendez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/.virtualenvs/experiments/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Se importan las librerías necesarias para el problema\n",
    "import category_encoders as ce\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, train_test_split\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando datos\n",
    "En primer lugar, vamos a cargar el dataset generado por el data scientist que se utilizó para entrenar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68206 entries, 0 to 68205\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   OPERA      68206 non-null  object\n",
      " 1   MES        68206 non-null  int64 \n",
      " 2   TIPOVUELO  68206 non-null  object\n",
      " 3   SIGLADES   68206 non-null  object\n",
      " 4   DIANOM     68206 non-null  object\n",
      " 5   atraso_15  68206 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset genere\n",
    "df = pd.read_csv('dataset_DS.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **OPERA** : Nombre de aerolínea que opera.\n",
    "* **MES** : Número de mes de operación del vuelo.\n",
    "* **TIPOVUELO** : Tipo de vuelo, I =Internacional, N =Nacional.\n",
    "* **DIANOM** : Día de la semana de operación del vuelo.\n",
    "* **SIGLADES** : Nombre ciudad destino.\n",
    "* **atraso_15** : 1 si **dif_min** > 15, 0 si no (variable objetivo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Escoger el modelo que a tu criterio tenga un mejor performance, argumentando la decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto a **Experimentación** el Data Scientist escoge dos modelos: logistic regression y Xgboost a partir de su conocimiento y afirmando que ambos modelos son simples y ofrecen buen desempeño. Sin embargo, en sus procesos de entrenamiento no realiza validación cruzada (cross validation) para obtener resultados más cercanos a la realidad en cuanto a las metricas de desempeño. Vamos a intentar comparar ambos modelos con validación cruzada para así tener una mejor perspectiva de cual puede ser mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "attachments": {
    "4aea6cb0-fdd5-4aae-b0ee-f0aa7b439c81.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados reportados por el data scientist son los siguientes:\n",
    "\n",
    "![image.png](attachment:4aea6cb0-fdd5-4aae-b0ee-f0aa7b439c81.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a observar que resultados se obtienen cuando se aplica cross validation al entrenamiento del modelo de logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8159\n",
      "Standard Deviation accuracy: 0.0013\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data established by the data scientist\n",
    "X = pd.concat([pd.get_dummies(df['OPERA'], prefix = 'OPERA'),pd.get_dummies(df['TIPOVUELO'], prefix = 'TIPOVUELO'), pd.get_dummies(df['MES'], prefix = 'MES')], axis = 1)\n",
    "y = df['atraso_15']\n",
    "\n",
    "# Create your logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Create a StratifiedKFold cross-validator with balanced class weights\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform balanced cross-validation\n",
    "accuracy_scores = []\n",
    "reports = []\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Fit the model with balanced class weights\n",
    "    logreg.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Obtain confusion matrix\n",
    "    cf = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Store the accuracy score\n",
    "    accuracy_scores.append(accuracy)\n",
    "    # Store the confusion matrix\n",
    "    reports.append(cf)\n",
    "\n",
    "# Calculate and print the average accuracy score across folds\n",
    "avg_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "sdt_accuracy = np.std(accuracy_scores)\n",
    "print(f'Average accuracy: {avg_accuracy:.4f}')\n",
    "print(f'Standard Deviation accuracy: {sdt_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.8158519897797083\n",
      "Average Recall: 0.5118242374651862\n",
      "Average F1-score: 0.4767868970861177\n"
     ]
    }
   ],
   "source": [
    "# Analyze the aggregated classification reports\n",
    "# For example, you can calculate the average metrics across all folds\n",
    "avg_precision = sum([cr['accuracy'] for cr in reports]) / len(reports)\n",
    "avg_recall = sum([cr['macro avg']['recall'] for cr in reports]) / len(reports)\n",
    "avg_f1_score = sum([cr['macro avg']['f1-score'] for cr in reports]) / len(reports)\n",
    "\n",
    "# Print the aggregated results\n",
    "print(\"Average Precision:\", avg_precision)\n",
    "print(\"Average Recall:\", avg_recall)\n",
    "print(\"Average F1-score:\", avg_f1_score)"
   ]
  },
  {
   "attachments": {
    "a97eaa62-9803-4f81-bf61-307d6ed6816d.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "Los resultados reportados por el data scientist son los siguientes:\n",
    "\n",
    "![image.png](attachment:a97eaa62-9803-4f81-bf61-307d6ed6816d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a observar que resultados se obtienen cuando se aplica cross validation al entrenamiento del modelo de xgboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8175\n",
      "Standard Deviation accuracy: 0.0008\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data established by the data scientist\n",
    "X = pd.concat([pd.get_dummies(df['OPERA'], prefix = 'OPERA'),pd.get_dummies(df['TIPOVUELO'], prefix = 'TIPOVUELO'), pd.get_dummies(df['MES'], prefix = 'MES')], axis = 1)\n",
    "y = df['atraso_15']\n",
    "\n",
    "# Creating xgboost model\n",
    "modelxgb = xgb.XGBClassifier(random_state=1, learning_rate=0.01)\n",
    "\n",
    "# Create a StratifiedKFold cross-validator with balanced class weights\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform balanced cross-validation\n",
    "accuracy_scores = []\n",
    "reports = []\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Fit the model with balanced class weights\n",
    "    modelxgb.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = modelxgb.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Obtain confusion matrix\n",
    "    cf = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Store the accuracy score\n",
    "    accuracy_scores.append(accuracy)\n",
    "    # Store the confusion matrix\n",
    "    reports.append(cf)\n",
    "\n",
    "# Calculate and print the average accuracy score across folds\n",
    "avg_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "sdt_accuracy = np.std(accuracy_scores)\n",
    "print(f'Average accuracy: {avg_accuracy:.4f}')\n",
    "print(f'Standard Deviation accuracy: {sdt_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.8174647446797259\n",
      "Average Recall: 0.5106685962189371\n",
      "Average F1-score: 0.4725050567399383\n"
     ]
    }
   ],
   "source": [
    "# Analyze the aggregated classification reports\n",
    "# For example, you can calculate the average metrics across all folds\n",
    "avg_precision = sum([cr['accuracy'] for cr in reports]) / len(reports)\n",
    "avg_recall = sum([cr['macro avg']['recall'] for cr in reports]) / len(reports)\n",
    "avg_f1_score = sum([cr['macro avg']['f1-score'] for cr in reports]) / len(reports)\n",
    "\n",
    "# Print the aggregated results\n",
    "print(\"Average Precision:\", avg_precision)\n",
    "print(\"Average Recall:\", avg_recall)\n",
    "print(\"Average F1-score:\", avg_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de significancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los anteriores resultados podemos observar que, utilizando cross validation, ambos modelos dan resultados consistentes con lo que el Data Scientist reportó en sus pruebas y además ambos modelos tienen resultados muy similares aun con un entrenamiento usando cross validation.\n",
    "\n",
    "Teniendo en cuenta que ambos modelos obtienen resultados muy cercanos en las metricas de desempeño, es importante realizar una prueba de significancia estadística para decidir cual de los dos es mejor. Para este caso vamos a utilizar la **prueba de Mcnemar**. Al comparar dos modelos XGBoost y Regresión Logística, la prueba de McNemar se puede utilizar para determinar si existe una diferencia estadísticamente significativa en su desempeño en términos de predecir el mismo conjunto de muestras. Además, como no hay una diferencia considerable entre el proceso de entrenamiento sin validación cruzada (realizado por el data scientist) y el proceso de entrenamiento con cross validation, utilizaremos el proceso del data scientist a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McNemar's test p-value: 1.0\n",
      "There is no statistically significant difference between the two models.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data established by the data scientist\n",
    "X = pd.concat([pd.get_dummies(df['OPERA'], prefix = 'OPERA'),pd.get_dummies(df['TIPOVUELO'], prefix = 'TIPOVUELO'), pd.get_dummies(df['MES'], prefix = 'MES')], axis = 1)\n",
    "y = df['atraso_15']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "\n",
    "# Train an XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(random_state=1, learning_rate=0.01)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate the contingency table\n",
    "table = np.array([y_test.values,\n",
    "                  y_pred_logreg,\n",
    "                  y_pred_xgb])\n",
    "contingency_table = mcnemar(table)\n",
    "\n",
    "\n",
    "# Print the result\n",
    "print(\"McNemar's test p-value:\", contingency_table.pvalue)\n",
    "\n",
    "# Perform a significance test at a significance level of 0.05\n",
    "alpha = 0.05\n",
    "if contingency_table.pvalue < alpha:\n",
    "    print(\"There is a statistically significant difference between the two models.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the two models.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prueba estadistica nos indica que no hay diferencia significativa entre los modelos. Por lo tanto, podemos decidir usando el **AIC (Akaike Information Criterion)** que indica el nivel de complejidad de cada modelo. En este caso, el modelo que tenga un menor AIC sera el modelo menos complejo y por ende el mejor para la tarea en cuestión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC de logistic regression: 73.63009322070988\n",
      "AIC de xgboost: 73.63333187448028\n"
     ]
    }
   ],
   "source": [
    "def calculate_aic(model, X_train, y_train):\n",
    "    # Obtain the AIC value\n",
    "    model_aic = 2 * (model.score(X_train, y_train) - model.score(X_train, model.predict(X_train))) + 2 * X_train.shape[1]\n",
    "    return model_aic\n",
    "\n",
    "log_reg_aic = calculate_aic(logreg, X_train, y_train)\n",
    "xgboost_aic = calculate_aic(xgb_model, X_train, y_train)\n",
    "print(f'AIC de logistic regression: {log_reg_aic}')\n",
    "print(f'AIC de xgboost: {xgboost_aic}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vista de que todas las metricas evaluadas no demuestran una diferencia significativa, es mejor elegir el modelo que sea más robusto por concepto y que este mejor capacitado para evitar futuros overfittings. Por lo tanto, para este caso, **se escoge el modelo xgboost**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementar mejoras sobre el modelo escogiendo la o las técnicas que prefieras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las mejoras que podemos intentar es utilizar otro encoder que no sea generado a partir de la función get_dummies() ya que este metodo de codificación genera una alta dimensionalidad en los datos de entrenamiento. Por lo tanto, podemos realizar un entrenamiento con un **Binary Encoder** y analizar si obtenemos mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPERA</th>\n",
       "      <th>MES</th>\n",
       "      <th>TIPOVUELO</th>\n",
       "      <th>SIGLADES</th>\n",
       "      <th>DIANOM</th>\n",
       "      <th>atraso_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sky Airline</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>Antofagasta</td>\n",
       "      <td>Viernes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grupo LATAM</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>Concepcion</td>\n",
       "      <td>Jueves</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grupo LATAM</td>\n",
       "      <td>9</td>\n",
       "      <td>N</td>\n",
       "      <td>Arica</td>\n",
       "      <td>Miercoles</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grupo LATAM</td>\n",
       "      <td>11</td>\n",
       "      <td>N</td>\n",
       "      <td>Iquique</td>\n",
       "      <td>Viernes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sky Airline</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>Valdivia</td>\n",
       "      <td>Lunes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68201</th>\n",
       "      <td>Grupo LATAM</td>\n",
       "      <td>7</td>\n",
       "      <td>I</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68202</th>\n",
       "      <td>Sky Airline</td>\n",
       "      <td>6</td>\n",
       "      <td>N</td>\n",
       "      <td>La Serena</td>\n",
       "      <td>Viernes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68203</th>\n",
       "      <td>Grupo LATAM</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>Temuco</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68204</th>\n",
       "      <td>Grupo LATAM</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Jueves</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68205</th>\n",
       "      <td>Grupo LATAM</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>Calama</td>\n",
       "      <td>Martes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68206 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             OPERA  MES TIPOVUELO      SIGLADES     DIANOM  atraso_15\n",
       "0      Sky Airline    3         N   Antofagasta    Viernes          0\n",
       "1      Grupo LATAM    7         N    Concepcion     Jueves          0\n",
       "2      Grupo LATAM    9         N         Arica  Miercoles          0\n",
       "3      Grupo LATAM   11         N       Iquique    Viernes          0\n",
       "4      Sky Airline    5         N      Valdivia      Lunes          0\n",
       "...            ...  ...       ...           ...        ...        ...\n",
       "68201  Grupo LATAM    7         I     Sao Paulo    Domingo          0\n",
       "68202  Sky Airline    6         N     La Serena    Viernes          1\n",
       "68203  Grupo LATAM    5         N        Temuco    Domingo          0\n",
       "68204  Grupo LATAM    1         I  Buenos Aires     Jueves          0\n",
       "68205  Grupo LATAM    2         N        Calama     Martes          0\n",
       "\n",
       "[68206 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after Binary Encoding:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPERA_0</th>\n",
       "      <th>OPERA_1</th>\n",
       "      <th>OPERA_2</th>\n",
       "      <th>OPERA_3</th>\n",
       "      <th>OPERA_4</th>\n",
       "      <th>MES</th>\n",
       "      <th>TIPOVUELO_0</th>\n",
       "      <th>TIPOVUELO_1</th>\n",
       "      <th>SIGLADES_0</th>\n",
       "      <th>SIGLADES_1</th>\n",
       "      <th>SIGLADES_2</th>\n",
       "      <th>SIGLADES_3</th>\n",
       "      <th>SIGLADES_4</th>\n",
       "      <th>SIGLADES_5</th>\n",
       "      <th>DIANOM_0</th>\n",
       "      <th>DIANOM_1</th>\n",
       "      <th>DIANOM_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68201</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68202</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68203</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68204</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68205</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68206 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       OPERA_0  OPERA_1  OPERA_2  OPERA_3  OPERA_4  MES  TIPOVUELO_0  \\\n",
       "0            0        0        0        0        1    3            0   \n",
       "1            0        0        0        1        0    7            0   \n",
       "2            0        0        0        1        0    9            0   \n",
       "3            0        0        0        1        0   11            0   \n",
       "4            0        0        0        0        1    5            0   \n",
       "...        ...      ...      ...      ...      ...  ...          ...   \n",
       "68201        0        0        0        1        0    7            1   \n",
       "68202        0        0        0        0        1    6            0   \n",
       "68203        0        0        0        1        0    5            0   \n",
       "68204        0        0        0        1        0    1            1   \n",
       "68205        0        0        0        1        0    2            0   \n",
       "\n",
       "       TIPOVUELO_1  SIGLADES_0  SIGLADES_1  SIGLADES_2  SIGLADES_3  \\\n",
       "0                1           0           0           0           0   \n",
       "1                1           0           0           0           0   \n",
       "2                1           0           0           0           0   \n",
       "3                1           0           0           0           1   \n",
       "4                1           0           0           0           1   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "68201            0           0           1           0           0   \n",
       "68202            1           0           1           0           1   \n",
       "68203            1           0           0           1           1   \n",
       "68204            0           0           0           0           1   \n",
       "68205            1           0           0           1           0   \n",
       "\n",
       "       SIGLADES_4  SIGLADES_5  DIANOM_0  DIANOM_1  DIANOM_2  \n",
       "0               0           1         0         0         1  \n",
       "1               1           0         0         1         0  \n",
       "2               1           1         0         1         1  \n",
       "3               0           0         0         0         1  \n",
       "4               0           1         1         0         0  \n",
       "...           ...         ...       ...       ...       ...  \n",
       "68201           1           1         1         0         1  \n",
       "68202           0           1         0         0         1  \n",
       "68203           0           0         1         0         1  \n",
       "68204           1           0         0         1         0  \n",
       "68205           1           1         1         1         1  \n",
       "\n",
       "[68206 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an instance of BinaryEncoder\n",
    "encoder = ce.BinaryEncoder()\n",
    "\n",
    "# Apply binary encoding to the dataframe\n",
    "df_encoded = encoder.fit_transform(df.loc[:, df.columns != 'atraso_15'])\n",
    "\n",
    "# Show the original dataframe\n",
    "print(\"Original DataFrame:\")\n",
    "display(df)\n",
    "\n",
    "# Show the dataframe after binary encoding\n",
    "print(\"\\nDataFrame after Binary Encoding:\")\n",
    "display(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este metodo pasamos de tener 37 columnas a 18 columnas reduciendo considerablemente la dimensionalidad del dataset de entrenamiento. Ahora vamos a analizar si las metricas de desempeño cambian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8151\n",
      "Standard Deviation accuracy: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data established by the data scientist\n",
    "X = df_encoded.loc[:, df_encoded.columns != 'atraso_15']\n",
    "y = df_encoded['atraso_15']\n",
    "\n",
    "# Creating xgboost model\n",
    "modelxgb = xgb.XGBClassifier(random_state=1, learning_rate=0.01)\n",
    "\n",
    "# Create a StratifiedKFold cross-validator with balanced class weights\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform balanced cross-validation\n",
    "accuracy_scores = []\n",
    "reports = []\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Fit the model with balanced class weights\n",
    "    modelxgb.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = modelxgb.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Obtain confusion matrix\n",
    "    cf = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Store the accuracy score\n",
    "    accuracy_scores.append(accuracy)\n",
    "    # Store the confusion matrix\n",
    "    reports.append(cf)\n",
    "\n",
    "# Calculate and print the average accuracy score across folds\n",
    "avg_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "sdt_accuracy = np.std(accuracy_scores)\n",
    "print(f'Average accuracy: {avg_accuracy:.4f}')\n",
    "print(f'Standard Deviation accuracy: {sdt_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.8151189078406731\n",
      "Average Recall: 0.500618177686859\n",
      "Average F1-score: 0.45055755625431326\n"
     ]
    }
   ],
   "source": [
    "# Analyze the aggregated classification reports\n",
    "# For example, you can calculate the average metrics across all folds\n",
    "avg_precision = sum([cr['accuracy'] for cr in reports]) / len(reports)\n",
    "avg_recall = sum([cr['macro avg']['recall'] for cr in reports]) / len(reports)\n",
    "avg_f1_score = sum([cr['macro avg']['f1-score'] for cr in reports]) / len(reports)\n",
    "\n",
    "# Print the aggregated results\n",
    "print(\"Average Precision:\", avg_precision)\n",
    "print(\"Average Recall:\", avg_recall)\n",
    "print(\"Average F1-score:\", avg_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta que para el caso con 37 variables la precision del modelo fue de 81.74% y para este caso con 18 variables tomadas a partir del Binary Encoder la precisión fue de 81.51% podemos trabajar con el dataset procesado con el Binary Encoder ya que reduce dimensionalidad del dataset sin perder performance de manera significativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning - Optuna\n",
    "\n",
    "En el trabajo realizado por el data scientist, se encontró que se intentó una optimización de hiperparámetros utilizando el metodo **GridSearch**. Este metodo aunque muy conocido, es el más pesado computacionalmente y no permite probar multiples combinaciones de hiperparametros que quizas permitan encontrar un mejor desempeño en el modelo. Optuna, es una libreria que permite realizar esa optimización sin ser tan demandante en recursos computacionales. Vamos a probar si es posible encontrar un mejor resultado al optimizar con Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-21 20:27:32,614]\u001b[0m A new study created in memory with name: no-name-ce65e0df-327a-405c-982a-a054fb02e012\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:33,685]\u001b[0m Trial 0 finished with value: 0.8209969788519638 and parameters: {'n_estimators': 70, 'max_depth': 7, 'learning_rate': 0.060257428006326524, 'gamma': 0.014321082927695381, 'min_child_weight': 7, 'subsample': 0.8772699385930416, 'colsample_bytree': 0.8527662913690989}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:35,718]\u001b[0m Trial 1 finished with value: 0.8201084059001243 and parameters: {'n_estimators': 160, 'max_depth': 6, 'learning_rate': 0.0499142114652393, 'gamma': 0.10979972263841918, 'min_child_weight': 3, 'subsample': 0.5649270711819377, 'colsample_bytree': 0.9151641071483769}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:36,951]\u001b[0m Trial 2 finished with value: 0.8176204016349742 and parameters: {'n_estimators': 110, 'max_depth': 5, 'learning_rate': 0.014925511222978905, 'gamma': 0.010580989627476724, 'min_child_weight': 5, 'subsample': 0.9344845174604981, 'colsample_bytree': 0.8974737320421045}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:40,022]\u001b[0m Trial 3 finished with value: 0.8198862626621646 and parameters: {'n_estimators': 190, 'max_depth': 9, 'learning_rate': 0.04663140403811791, 'gamma': 0.07368084453787116, 'min_child_weight': 1, 'subsample': 0.5526269925692959, 'colsample_bytree': 0.5395166746318563}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:41,097]\u001b[0m Trial 4 finished with value: 0.82068597831882 and parameters: {'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.0027084770106098268, 'gamma': 0.03330633036845574, 'min_child_weight': 1, 'subsample': 0.8276554155693056, 'colsample_bytree': 0.8322571644857634}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:43,762]\u001b[0m Trial 5 finished with value: 0.8194419761862449 and parameters: {'n_estimators': 160, 'max_depth': 10, 'learning_rate': 0.0017484427817307244, 'gamma': 0.06201186813814167, 'min_child_weight': 3, 'subsample': 0.6404532823149032, 'colsample_bytree': 0.6486485345829155}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:44,365]\u001b[0m Trial 6 finished with value: 0.818064688110894 and parameters: {'n_estimators': 110, 'max_depth': 6, 'learning_rate': 0.0991948355383354, 'gamma': 0.11705281138631668, 'min_child_weight': 10, 'subsample': 0.22214877156111534, 'colsample_bytree': 0.2356120987634195}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:45,006]\u001b[0m Trial 7 finished with value: 0.8199306913097565 and parameters: {'n_estimators': 50, 'max_depth': 10, 'learning_rate': 0.0918227850845268, 'gamma': 0.945653449766526, 'min_child_weight': 3, 'subsample': 0.8334840836716404, 'colsample_bytree': 0.44027929048690906}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:45,375]\u001b[0m Trial 8 finished with value: 0.8196196907766128 and parameters: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.0845387502684783, 'gamma': 0.018020849494277853, 'min_child_weight': 3, 'subsample': 0.24152988530887004, 'colsample_bytree': 0.7219560352153765}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:46,086]\u001b[0m Trial 9 finished with value: 0.8176204016349742 and parameters: {'n_estimators': 150, 'max_depth': 4, 'learning_rate': 0.009332709518975748, 'gamma': 0.3078168309456668, 'min_child_weight': 10, 'subsample': 0.1708497792939302, 'colsample_bytree': 0.3133249874360343}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:46,428]\u001b[0m Trial 10 finished with value: 0.8176204016349742 and parameters: {'n_estimators': 80, 'max_depth': 8, 'learning_rate': 0.019970588975768026, 'gamma': 0.011063773632646797, 'min_child_weight': 8, 'subsample': 0.9968026681305631, 'colsample_bytree': 0.11977349702178308}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:47,762]\u001b[0m Trial 11 finished with value: 0.8197085480717967 and parameters: {'n_estimators': 80, 'max_depth': 8, 'learning_rate': 0.003243616284667781, 'gamma': 0.0271156780466879, 'min_child_weight': 7, 'subsample': 0.7640959865311404, 'colsample_bytree': 0.7736062779481665}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:52,326]\u001b[0m Trial 12 finished with value: 0.820730406966412 and parameters: {'n_estimators': 80, 'max_depth': 8, 'learning_rate': 0.00534839030462618, 'gamma': 0.031073722135560228, 'min_child_weight': 6, 'subsample': 0.7743842965348667, 'colsample_bytree': 0.9858968607231469}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:53,693]\u001b[0m Trial 13 finished with value: 0.8197529767193886 and parameters: {'n_estimators': 80, 'max_depth': 7, 'learning_rate': 0.006601834539322393, 'gamma': 0.0302981426725175, 'min_child_weight': 6, 'subsample': 0.694166379979676, 'colsample_bytree': 0.9914270415925546}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:55,347]\u001b[0m Trial 14 finished with value: 0.8197974053669806 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.0058842394716151145, 'gamma': 0.017869875428588946, 'min_child_weight': 8, 'subsample': 0.8805991648287465, 'colsample_bytree': 0.9973434025997562}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:57,610]\u001b[0m Trial 15 finished with value: 0.8203749777856763 and parameters: {'n_estimators': 130, 'max_depth': 8, 'learning_rate': 0.0010393308195511635, 'gamma': 0.040794143481827604, 'min_child_weight': 5, 'subsample': 0.7403501913342564, 'colsample_bytree': 0.8362825051737138}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:57,991]\u001b[0m Trial 16 finished with value: 0.8176204016349742 and parameters: {'n_estimators': 70, 'max_depth': 3, 'learning_rate': 0.026684104000081373, 'gamma': 0.016651053197140653, 'min_child_weight': 7, 'subsample': 0.94246222256156, 'colsample_bytree': 0.6861452288219798}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:27:59,388]\u001b[0m Trial 17 finished with value: 0.8186866891771815 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.012168965273886799, 'gamma': 0.04412682235539608, 'min_child_weight': 9, 'subsample': 0.42350125988445886, 'colsample_bytree': 0.7899365061817976}. Best is trial 0 with value: 0.8209969788519638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:00,953]\u001b[0m Trial 18 finished with value: 0.8210858361471477 and parameters: {'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.025865243625973824, 'gamma': 0.02057189520348276, 'min_child_weight': 6, 'subsample': 0.8035892629814985, 'colsample_bytree': 0.8855533941147935}. Best is trial 18 with value: 0.8210858361471477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:03,109]\u001b[0m Trial 19 finished with value: 0.82068597831882 and parameters: {'n_estimators': 130, 'max_depth': 9, 'learning_rate': 0.02706266341495228, 'gamma': 0.010848071369976696, 'min_child_weight': 4, 'subsample': 0.8552617804847537, 'colsample_bytree': 0.6547090038045773}. Best is trial 18 with value: 0.8210858361471477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:04,656]\u001b[0m Trial 20 finished with value: 0.8207748356140039 and parameters: {'n_estimators': 60, 'max_depth': 10, 'learning_rate': 0.04290633117233486, 'gamma': 0.01881241198132523, 'min_child_weight': 7, 'subsample': 0.6611221236954532, 'colsample_bytree': 0.8871603174979461}. Best is trial 18 with value: 0.8210858361471477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:06,237]\u001b[0m Trial 21 finished with value: 0.8209969788519638 and parameters: {'n_estimators': 60, 'max_depth': 10, 'learning_rate': 0.043935793310288636, 'gamma': 0.019813710794894763, 'min_child_weight': 7, 'subsample': 0.6641214423686919, 'colsample_bytree': 0.890627366543784}. Best is trial 18 with value: 0.8210858361471477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:07,398]\u001b[0m Trial 22 finished with value: 0.8209081215567798 and parameters: {'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.03356489059750036, 'gamma': 0.019658326591250393, 'min_child_weight': 8, 'subsample': 0.7954968978302868, 'colsample_bytree': 0.7483063816702032}. Best is trial 18 with value: 0.8210858361471477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:09,686]\u001b[0m Trial 23 finished with value: 0.8197529767193886 and parameters: {'n_estimators': 90, 'max_depth': 10, 'learning_rate': 0.06085469238991759, 'gamma': 0.013448159174143623, 'min_child_weight': 6, 'subsample': 0.6946756757532876, 'colsample_bytree': 0.8514034375860504}. Best is trial 18 with value: 0.8210858361471477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:11,006]\u001b[0m Trial 24 finished with value: 0.8209525502043717 and parameters: {'n_estimators': 60, 'max_depth': 9, 'learning_rate': 0.02087121378364545, 'gamma': 0.024321451205075804, 'min_child_weight': 9, 'subsample': 0.8873880872397041, 'colsample_bytree': 0.9259490290515262}. Best is trial 18 with value: 0.8210858361471477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:15,021]\u001b[0m Trial 25 finished with value: 0.8210858361471477 and parameters: {'n_estimators': 60, 'max_depth': 10, 'learning_rate': 0.034739539342178126, 'gamma': 0.015326912109172969, 'min_child_weight': 5, 'subsample': 0.6161239094167992, 'colsample_bytree': 0.8014942142998971}. Best is trial 18 with value: 0.8210858361471477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:18,401]\u001b[0m Trial 26 finished with value: 0.817931402168118 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.06636539072928963, 'gamma': 0.01046833680900005, 'min_child_weight': 4, 'subsample': 0.9902387054065168, 'colsample_bytree': 0.7981264660341755}. Best is trial 18 with value: 0.8210858361471477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:19,406]\u001b[0m Trial 27 finished with value: 0.8190865470055092 and parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.03157942579719518, 'gamma': 0.015420508644749262, 'min_child_weight': 5, 'subsample': 0.49709044671258507, 'colsample_bytree': 0.6112560776996095}. Best is trial 18 with value: 0.8210858361471477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:20,022]\u001b[0m Trial 28 finished with value: 0.8175315443397903 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.017532981167455764, 'gamma': 0.014207686922903164, 'min_child_weight': 4, 'subsample': 0.7609009524322944, 'colsample_bytree': 0.7280155033724822}. Best is trial 18 with value: 0.8210858361471477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:22,935]\u001b[0m Trial 29 finished with value: 0.8173538297494224 and parameters: {'n_estimators': 120, 'max_depth': 9, 'learning_rate': 0.06837468969684404, 'gamma': 0.022991661600008022, 'min_child_weight': 2, 'subsample': 0.6079854031723059, 'colsample_bytree': 0.9473869120223076}. Best is trial 18 with value: 0.8210858361471477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:24,374]\u001b[0m Trial 30 finished with value: 0.8209525502043717 and parameters: {'n_estimators': 90, 'max_depth': 7, 'learning_rate': 0.03882572388699887, 'gamma': 0.024831046520250977, 'min_child_weight': 6, 'subsample': 0.5986724612047234, 'colsample_bytree': 0.8563766560236382}. Best is trial 18 with value: 0.8210858361471477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:25,940]\u001b[0m Trial 31 finished with value: 0.8201528345477164 and parameters: {'n_estimators': 60, 'max_depth': 10, 'learning_rate': 0.05148132418361843, 'gamma': 0.015285470857084097, 'min_child_weight': 7, 'subsample': 0.726941879453264, 'colsample_bytree': 0.9069330172503935}. Best is trial 18 with value: 0.8210858361471477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:27,554]\u001b[0m Trial 32 finished with value: 0.820641549671228 and parameters: {'n_estimators': 60, 'max_depth': 10, 'learning_rate': 0.049206757392513616, 'gamma': 0.01293830473383399, 'min_child_weight': 5, 'subsample': 0.6873816213203991, 'colsample_bytree': 0.920337171466237}. Best is trial 18 with value: 0.8210858361471477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:29,012]\u001b[0m Trial 33 finished with value: 0.8212191220899235 and parameters: {'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.03458979529951407, 'gamma': 0.02206591788578173, 'min_child_weight': 7, 'subsample': 0.8148155578848392, 'colsample_bytree': 0.8116255430297682}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:31,025]\u001b[0m Trial 34 finished with value: 0.8209969788519638 and parameters: {'n_estimators': 90, 'max_depth': 9, 'learning_rate': 0.02744232833707961, 'gamma': 0.010322581039922696, 'min_child_weight': 6, 'subsample': 0.9117476346504149, 'colsample_bytree': 0.7982015832521188}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:32,604]\u001b[0m Trial 35 finished with value: 0.8209525502043717 and parameters: {'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.03564501834525886, 'gamma': 0.03408088039694746, 'min_child_weight': 8, 'subsample': 0.8386640995226273, 'colsample_bytree': 0.8469294598046709}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:35,276]\u001b[0m Trial 36 finished with value: 0.8207748356140039 and parameters: {'n_estimators': 180, 'max_depth': 8, 'learning_rate': 0.021914158744226343, 'gamma': 0.04572068989863546, 'min_child_weight': 4, 'subsample': 0.8198426786852462, 'colsample_bytree': 0.7415766476688157}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:36,333]\u001b[0m Trial 37 finished with value: 0.8208192642615959 and parameters: {'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.05628999649950936, 'gamma': 0.024061761440764124, 'min_child_weight': 9, 'subsample': 0.9155412404419045, 'colsample_bytree': 0.8011369035119065}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:37,384]\u001b[0m Trial 38 finished with value: 0.8176204016349742 and parameters: {'n_estimators': 110, 'max_depth': 6, 'learning_rate': 0.014755531429475988, 'gamma': 0.06320560892468137, 'min_child_weight': 5, 'subsample': 0.7937702470847078, 'colsample_bytree': 0.5749100025883235}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:38,371]\u001b[0m Trial 39 finished with value: 0.820597121023636 and parameters: {'n_estimators': 50, 'max_depth': 10, 'learning_rate': 0.07701572555630627, 'gamma': 0.013102582658893455, 'min_child_weight': 6, 'subsample': 0.8362641193863446, 'colsample_bytree': 0.6971517520708467}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:40,068]\u001b[0m Trial 40 finished with value: 0.820730406966412 and parameters: {'n_estimators': 90, 'max_depth': 8, 'learning_rate': 0.040135291101188394, 'gamma': 0.020805927025741487, 'min_child_weight': 7, 'subsample': 0.9562527210991054, 'colsample_bytree': 0.9502710493394166}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:41,599]\u001b[0m Trial 41 finished with value: 0.8205526923760441 and parameters: {'n_estimators': 60, 'max_depth': 10, 'learning_rate': 0.04723624340979108, 'gamma': 0.02045728507313269, 'min_child_weight': 7, 'subsample': 0.7228245013024917, 'colsample_bytree': 0.8776582118679004}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:43,421]\u001b[0m Trial 42 finished with value: 0.8195308334814289 and parameters: {'n_estimators': 70, 'max_depth': 10, 'learning_rate': 0.08195050750417966, 'gamma': 0.01658456711600068, 'min_child_weight': 8, 'subsample': 0.6426926657981218, 'colsample_bytree': 0.8880724544430725}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:44,515]\u001b[0m Trial 43 finished with value: 0.8211302647947396 and parameters: {'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.042486363545309026, 'gamma': 0.026806734421920053, 'min_child_weight': 7, 'subsample': 0.8656024496814215, 'colsample_bytree': 0.827480100690843}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:45,721]\u001b[0m Trial 44 finished with value: 0.8198862626621646 and parameters: {'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.09915929662510496, 'gamma': 0.028489267813373496, 'min_child_weight': 6, 'subsample': 0.8750724775706333, 'colsample_bytree': 0.8338007118400268}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:46,379]\u001b[0m Trial 45 finished with value: 0.8176204016349742 and parameters: {'n_estimators': 80, 'max_depth': 4, 'learning_rate': 0.05578938913673305, 'gamma': 0.03564874217782387, 'min_child_weight': 8, 'subsample': 0.801822861046598, 'colsample_bytree': 0.766937539863552}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:47,544]\u001b[0m Trial 46 finished with value: 0.82068597831882 and parameters: {'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.03127906855858199, 'gamma': 0.027239677675545585, 'min_child_weight': 7, 'subsample': 0.8694205559568684, 'colsample_bytree': 0.9476653023774666}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:48,866]\u001b[0m Trial 47 finished with value: 0.8212191220899235 and parameters: {'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.023192025222363147, 'gamma': 0.012650989218149784, 'min_child_weight': 6, 'subsample': 0.761488865637257, 'colsample_bytree': 0.8047994578670716}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:51,663]\u001b[0m Trial 48 finished with value: 0.8209081215567798 and parameters: {'n_estimators': 150, 'max_depth': 8, 'learning_rate': 0.024067226325220365, 'gamma': 0.01258794102460157, 'min_child_weight': 5, 'subsample': 0.7449251715200632, 'colsample_bytree': 0.813058960665291}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:52,822]\u001b[0m Trial 49 finished with value: 0.8202861204904923 and parameters: {'n_estimators': 80, 'max_depth': 8, 'learning_rate': 0.020436787060906778, 'gamma': 0.014748658224908824, 'min_child_weight': 6, 'subsample': 0.7843837296242742, 'colsample_bytree': 0.7025371040702771}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:54,523]\u001b[0m Trial 50 finished with value: 0.8208636929091878 and parameters: {'n_estimators': 80, 'max_depth': 9, 'learning_rate': 0.029000103805950927, 'gamma': 0.052906981505919555, 'min_child_weight': 5, 'subsample': 0.8094270013435942, 'colsample_bytree': 0.7689673173239999}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:55,611]\u001b[0m Trial 51 finished with value: 0.8201528345477164 and parameters: {'n_estimators': 70, 'max_depth': 7, 'learning_rate': 0.03705264486211147, 'gamma': 0.0166041987229605, 'min_child_weight': 7, 'subsample': 0.8997559617061436, 'colsample_bytree': 0.8368430223793814}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:56,372]\u001b[0m Trial 52 finished with value: 0.8191309756531011 and parameters: {'n_estimators': 60, 'max_depth': 7, 'learning_rate': 0.016955458351771487, 'gamma': 0.012027604291707855, 'min_child_weight': 6, 'subsample': 0.8553189310832502, 'colsample_bytree': 0.7547904400758499}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:57,641]\u001b[0m Trial 53 finished with value: 0.8212191220899235 and parameters: {'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.02512267711083653, 'gamma': 0.02230936128930568, 'min_child_weight': 8, 'subsample': 0.7604078080186076, 'colsample_bytree': 0.8195504743728762}. Best is trial 33 with value: 0.8212191220899235.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:28:58,964]\u001b[0m Trial 54 finished with value: 0.8212635507375156 and parameters: {'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.025735596358688977, 'gamma': 0.031418857979262575, 'min_child_weight': 9, 'subsample': 0.7191058221452544, 'colsample_bytree': 0.8677287925772513}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:00,309]\u001b[0m Trial 55 finished with value: 0.8211302647947396 and parameters: {'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.023022172477515545, 'gamma': 0.03463098273831141, 'min_child_weight': 9, 'subsample': 0.7773138307630444, 'colsample_bytree': 0.8825908372584894}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:01,876]\u001b[0m Trial 56 finished with value: 0.820597121023636 and parameters: {'n_estimators': 80, 'max_depth': 8, 'learning_rate': 0.017672021311162116, 'gamma': 0.03703429665233907, 'min_child_weight': 10, 'subsample': 0.7651409349750983, 'colsample_bytree': 0.9674983507539706}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:02,802]\u001b[0m Trial 57 finished with value: 0.820730406966412 and parameters: {'n_estimators': 50, 'max_depth': 8, 'learning_rate': 0.024018582832008886, 'gamma': 0.030778487252308296, 'min_child_weight': 9, 'subsample': 0.7382742786875771, 'colsample_bytree': 0.8711541686820196}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:04,550]\u001b[0m Trial 58 finished with value: 0.8204194064332682 and parameters: {'n_estimators': 90, 'max_depth': 8, 'learning_rate': 0.014385090347289768, 'gamma': 0.0413462127397216, 'min_child_weight': 9, 'subsample': 0.6976715151645024, 'colsample_bytree': 0.9199590710064903}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:05,510]\u001b[0m Trial 59 finished with value: 0.8195752621290208 and parameters: {'n_estimators': 70, 'max_depth': 7, 'learning_rate': 0.02354598705164945, 'gamma': 0.029777827637562645, 'min_child_weight': 10, 'subsample': 0.7752904878122476, 'colsample_bytree': 0.727109381580773}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:07,364]\u001b[0m Trial 60 finished with value: 0.8211302647947396 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.029510943671550032, 'gamma': 0.0347809863263071, 'min_child_weight': 8, 'subsample': 0.8294013942147259, 'colsample_bytree': 0.8211681290949199}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:09,151]\u001b[0m Trial 61 finished with value: 0.8211746934423316 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.02735192818470319, 'gamma': 0.025813024478213435, 'min_child_weight': 8, 'subsample': 0.8301177943964978, 'colsample_bytree': 0.8115821957984521}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:11,291]\u001b[0m Trial 62 finished with value: 0.8205526923760441 and parameters: {'n_estimators': 110, 'max_depth': 8, 'learning_rate': 0.0424899802656959, 'gamma': 0.023335512785829148, 'min_child_weight': 9, 'subsample': 0.857546699733922, 'colsample_bytree': 0.7802785668297874}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:13,403]\u001b[0m Trial 63 finished with value: 0.8212635507375156 and parameters: {'n_estimators': 120, 'max_depth': 7, 'learning_rate': 0.03289854972685119, 'gamma': 0.02717640045009028, 'min_child_weight': 8, 'subsample': 0.7211677399894743, 'colsample_bytree': 0.8626146261860759}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:15,662]\u001b[0m Trial 64 finished with value: 0.8210414074995557 and parameters: {'n_estimators': 120, 'max_depth': 7, 'learning_rate': 0.034532951864978886, 'gamma': 0.02606356230224509, 'min_child_weight': 8, 'subsample': 0.7210233980171479, 'colsample_bytree': 0.8247762295809163}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:18,026]\u001b[0m Trial 65 finished with value: 0.8209525502043717 and parameters: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.027840083402446845, 'gamma': 0.019071150458505434, 'min_child_weight': 8, 'subsample': 0.8189225462460207, 'colsample_bytree': 0.865632555917932}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:19,766]\u001b[0m Trial 66 finished with value: 0.82068597831882 and parameters: {'n_estimators': 140, 'max_depth': 6, 'learning_rate': 0.04064169227840813, 'gamma': 0.0218574541303422, 'min_child_weight': 7, 'subsample': 0.7063204916771034, 'colsample_bytree': 0.7766505899839568}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:21,476]\u001b[0m Trial 67 finished with value: 0.8209525502043717 and parameters: {'n_estimators': 110, 'max_depth': 7, 'learning_rate': 0.030774324887922137, 'gamma': 0.01751165345196492, 'min_child_weight': 8, 'subsample': 0.7562670502873776, 'colsample_bytree': 0.8576339418129515}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:25,223]\u001b[0m Trial 68 finished with value: 0.820730406966412 and parameters: {'n_estimators': 130, 'max_depth': 9, 'learning_rate': 0.019446651718495897, 'gamma': 0.027866244436406194, 'min_child_weight': 7, 'subsample': 0.682691037154277, 'colsample_bytree': 0.91830704145199}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:27,845]\u001b[0m Trial 69 finished with value: 0.8201972631953084 and parameters: {'n_estimators': 120, 'max_depth': 8, 'learning_rate': 0.045072281984418136, 'gamma': 0.022085350483738633, 'min_child_weight': 8, 'subsample': 0.7451033076231305, 'colsample_bytree': 0.8226037266271984}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:30,144]\u001b[0m Trial 70 finished with value: 0.8211302647947396 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.025590565254728546, 'gamma': 0.017748109176747434, 'min_child_weight': 10, 'subsample': 0.6613456496243182, 'colsample_bytree': 0.7416622587220817}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:31,862]\u001b[0m Trial 71 finished with value: 0.8211746934423316 and parameters: {'n_estimators': 80, 'max_depth': 8, 'learning_rate': 0.022071053943745252, 'gamma': 0.03132226120680339, 'min_child_weight': 9, 'subsample': 0.7795653755747481, 'colsample_bytree': 0.8886399118263335}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:33,731]\u001b[0m Trial 72 finished with value: 0.8207748356140039 and parameters: {'n_estimators': 90, 'max_depth': 8, 'learning_rate': 0.035082311396165786, 'gamma': 0.03031856320054681, 'min_child_weight': 9, 'subsample': 0.7945318102523876, 'colsample_bytree': 0.9994618168538884}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:35,402]\u001b[0m Trial 73 finished with value: 0.8210858361471477 and parameters: {'n_estimators': 80, 'max_depth': 8, 'learning_rate': 0.032273460383239576, 'gamma': 0.025651512749155947, 'min_child_weight': 8, 'subsample': 0.8440748826420098, 'colsample_bytree': 0.9064895356111106}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:36,394]\u001b[0m Trial 74 finished with value: 0.8197085480717967 and parameters: {'n_estimators': 60, 'max_depth': 7, 'learning_rate': 0.021154217359137344, 'gamma': 0.039653767733817055, 'min_child_weight': 9, 'subsample': 0.8793292378485362, 'colsample_bytree': 0.8512011436679124}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:38,162]\u001b[0m Trial 75 finished with value: 0.820597121023636 and parameters: {'n_estimators': 80, 'max_depth': 9, 'learning_rate': 0.012437493510220684, 'gamma': 0.04761864284153116, 'min_child_weight': 7, 'subsample': 0.71463951371556, 'colsample_bytree': 0.8061049755309462}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:40,065]\u001b[0m Trial 76 finished with value: 0.8212191220899235 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.025187502330028207, 'gamma': 0.022137430300713447, 'min_child_weight': 8, 'subsample': 0.8132945837250249, 'colsample_bytree': 0.789429706485694}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:42,229]\u001b[0m Trial 77 finished with value: 0.8210858361471477 and parameters: {'n_estimators': 110, 'max_depth': 8, 'learning_rate': 0.02636494811049503, 'gamma': 0.020682009380639795, 'min_child_weight': 8, 'subsample': 0.7779699894212407, 'colsample_bytree': 0.7864326701472982}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:43,182]\u001b[0m Trial 78 finished with value: 0.818064688110894 and parameters: {'n_estimators': 90, 'max_depth': 6, 'learning_rate': 0.02002880108923241, 'gamma': 0.011305237964091329, 'min_child_weight': 9, 'subsample': 0.8135245312734184, 'colsample_bytree': 0.6687905191656367}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:44,928]\u001b[0m Trial 79 finished with value: 0.8210858361471477 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.02555404794086149, 'gamma': 0.01417004975554912, 'min_child_weight': 10, 'subsample': 0.7533490463212624, 'colsample_bytree': 0.8964939707516063}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:46,330]\u001b[0m Trial 80 finished with value: 0.8199306913097565 and parameters: {'n_estimators': 80, 'max_depth': 8, 'learning_rate': 0.01736345994039405, 'gamma': 0.01841650145448699, 'min_child_weight': 8, 'subsample': 0.8249419442182236, 'colsample_bytree': 0.7154218988367875}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:48,079]\u001b[0m Trial 81 finished with value: 0.8208192642615959 and parameters: {'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.031088859927086845, 'gamma': 0.02446795102208186, 'min_child_weight': 7, 'subsample': 0.8534523798252422, 'colsample_bytree': 0.8494143929209539}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:49,283]\u001b[0m Trial 82 finished with value: 0.8211302647947396 and parameters: {'n_estimators': 60, 'max_depth': 8, 'learning_rate': 0.03826272447268556, 'gamma': 0.0324514009969928, 'min_child_weight': 9, 'subsample': 0.7327819537858469, 'colsample_bytree': 0.8119487966850835}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:50,849]\u001b[0m Trial 83 finished with value: 0.8209969788519638 and parameters: {'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.028360355841556325, 'gamma': 0.025630664139355372, 'min_child_weight': 8, 'subsample': 0.8887826034060065, 'colsample_bytree': 0.87202599699884}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:51,774]\u001b[0m Trial 84 finished with value: 0.820641549671228 and parameters: {'n_estimators': 60, 'max_depth': 8, 'learning_rate': 0.05035147216991092, 'gamma': 0.02862765056492755, 'min_child_weight': 8, 'subsample': 0.8394084704583431, 'colsample_bytree': 0.7578863736561903}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:53,927]\u001b[0m Trial 85 finished with value: 0.8209525502043717 and parameters: {'n_estimators': 90, 'max_depth': 9, 'learning_rate': 0.023611660639873123, 'gamma': 0.02216426281695208, 'min_child_weight': 7, 'subsample': 0.7964086860500283, 'colsample_bytree': 0.8397818185992493}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:56,039]\u001b[0m Trial 86 finished with value: 0.8209969788519638 and parameters: {'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.03669555254304074, 'gamma': 0.015617309560735287, 'min_child_weight': 9, 'subsample': 0.766430514883579, 'colsample_bytree': 0.7931959295418467}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:29:57,571]\u001b[0m Trial 87 finished with value: 0.8175759729873823 and parameters: {'n_estimators': 180, 'max_depth': 3, 'learning_rate': 0.04494320792669986, 'gamma': 0.037608571744883586, 'min_child_weight': 1, 'subsample': 0.8060816625807743, 'colsample_bytree': 0.8957031695506454}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:30:00,464]\u001b[0m Trial 88 finished with value: 0.8208636929091878 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.033164470870913655, 'gamma': 0.03163696826132287, 'min_child_weight': 7, 'subsample': 0.926122057787678, 'colsample_bytree': 0.9357428339723308}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:30:01,619]\u001b[0m Trial 89 finished with value: 0.8208192642615959 and parameters: {'n_estimators': 50, 'max_depth': 8, 'learning_rate': 0.0219155638898646, 'gamma': 0.020144305845902887, 'min_child_weight': 8, 'subsample': 0.8649046792952683, 'colsample_bytree': 0.9675232083296502}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:30:04,045]\u001b[0m Trial 90 finished with value: 0.8209525502043717 and parameters: {'n_estimators': 80, 'max_depth': 9, 'learning_rate': 0.028427118008746494, 'gamma': 0.023375911654057814, 'min_child_weight': 9, 'subsample': 0.899122900884074, 'colsample_bytree': 0.8379570601400609}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:30:05,343]\u001b[0m Trial 91 finished with value: 0.8212191220899235 and parameters: {'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.02325324961707397, 'gamma': 0.03321769533712632, 'min_child_weight': 9, 'subsample': 0.7771560462449448, 'colsample_bytree': 0.8766540001487627}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:30:06,763]\u001b[0m Trial 92 finished with value: 0.8211302647947396 and parameters: {'n_estimators': 80, 'max_depth': 8, 'learning_rate': 0.019461581032718906, 'gamma': 0.027007956112545115, 'min_child_weight': 10, 'subsample': 0.7830771061847265, 'colsample_bytree': 0.8663736577388441}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:30:07,951]\u001b[0m Trial 93 finished with value: 0.8211746934423316 and parameters: {'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.024684389577743077, 'gamma': 0.033737450639511085, 'min_child_weight': 8, 'subsample': 0.7181326296964128, 'colsample_bytree': 0.8174247467278928}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:30:10,394]\u001b[0m Trial 94 finished with value: 0.8207748356140039 and parameters: {'n_estimators': 140, 'max_depth': 8, 'learning_rate': 0.02527075226263042, 'gamma': 0.03474059728409825, 'min_child_weight': 9, 'subsample': 0.7278470080755278, 'colsample_bytree': 0.8075816225630088}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:30:11,580]\u001b[0m Trial 95 finished with value: 0.8200639772525324 and parameters: {'n_estimators': 70, 'max_depth': 7, 'learning_rate': 0.02155280869243891, 'gamma': 0.03879703430780054, 'min_child_weight': 8, 'subsample': 0.6804642152805498, 'colsample_bytree': 0.8983162491787241}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:30:12,847]\u001b[0m Trial 96 finished with value: 0.8199751199573485 and parameters: {'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.0159880906519325, 'gamma': 0.03186074963447737, 'min_child_weight': 9, 'subsample': 0.7034598772133928, 'colsample_bytree': 0.7806978953786226}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:30:14,961]\u001b[0m Trial 97 finished with value: 0.8211746934423316 and parameters: {'n_estimators': 120, 'max_depth': 8, 'learning_rate': 0.01828886848791167, 'gamma': 0.0438793660548592, 'min_child_weight': 8, 'subsample': 0.7620529341815726, 'colsample_bytree': 0.8755494071702113}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:30:15,770]\u001b[0m Trial 98 finished with value: 0.8195308334814289 and parameters: {'n_estimators': 60, 'max_depth': 7, 'learning_rate': 0.022466493796420663, 'gamma': 0.01000959924289075, 'min_child_weight': 9, 'subsample': 0.7427320634523774, 'colsample_bytree': 0.7556494395362615}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 20:30:17,518]\u001b[0m Trial 99 finished with value: 0.8212635507375156 and parameters: {'n_estimators': 90, 'max_depth': 8, 'learning_rate': 0.027675790985352677, 'gamma': 0.01944359382384237, 'min_child_weight': 8, 'subsample': 0.7160940825790975, 'colsample_bytree': 0.9299820815800428}. Best is trial 54 with value: 0.8212635507375156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best performance was obtained with this parameters: {'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.025735596358688977, 'gamma': 0.031418857979262575, 'min_child_weight': 9, 'subsample': 0.7191058221452544, 'colsample_bytree': 0.8677287925772513}\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data established by the data scientist\n",
    "X = df_encoded.loc[:, df_encoded.columns != 'atraso_15']\n",
    "y = df_encoded['atraso_15']\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Define the objective function for Optuna to optimize\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200, step=10),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 0.01, 1),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.1, 1),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.1, 1),\n",
    "    }\n",
    "\n",
    "    # Create an XGBoost classifier with the hyperparameters\n",
    "    clf = xgb.XGBClassifier(**params)\n",
    "\n",
    "    # Train and evaluate the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n",
    "\n",
    "# Get the best hyperparameters from the study\n",
    "best_params = study.best_params\n",
    "print(f\"The best performance was obtained with this parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a entrenar el modelo con cross validation y esos hiperparámetros para observar si obtenemos un mejor desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8182\n",
      "Standard Deviation accuracy: 0.0012\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data established by the data scientist\n",
    "X = df_encoded.loc[:, df_encoded.columns != 'atraso_15']\n",
    "y = df_encoded['atraso_15']\n",
    "\n",
    "# Creating xgboost model\n",
    "modelxgb = xgb.XGBClassifier(**best_params, random_state=1)\n",
    "\n",
    "# Create a StratifiedKFold cross-validator with balanced class weights\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform balanced cross-validation\n",
    "accuracy_scores = []\n",
    "reports = []\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Fit the model with balanced class weights\n",
    "    modelxgb.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = modelxgb.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Obtain confusion matrix\n",
    "    cf = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Store the accuracy score\n",
    "    accuracy_scores.append(accuracy)\n",
    "    # Store the confusion matrix\n",
    "    reports.append(cf)\n",
    "\n",
    "# Calculate and print the average accuracy score across folds\n",
    "avg_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "sdt_accuracy = np.std(accuracy_scores)\n",
    "print(f'Average accuracy: {avg_accuracy:.4f}')\n",
    "print(f'Standard Deviation accuracy: {sdt_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta que para el caso **con 37 variables la precision del modelo fue de 81.74%**, despues de la optimización de hiperparámetros con Optuna **la precisión subio a 81.82%** manteniendo **menos dimensionalidad** en el dataset de entrenamiento (**18 variables**)\n",
    "\n",
    "Ahora vamos a guardar el modelo entrenado y el Binary Encoder para usarlos en la API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generando el modelo con Binary Encoder con Joblib para la API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['binary_encoder.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the encoder object to a file\n",
    "joblib.dump(encoder, 'binary_encoder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generando el modelo con Joblib para la API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgboost_model.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing data established by the data scientist\n",
    "X = df_encoded.loc[:, df_encoded.columns != 'atraso_15']\n",
    "y = df_encoded['atraso_15']\n",
    "\n",
    "# Creating xgboost model\n",
    "modelxgb = xgb.XGBClassifier(**best_params, random_state=1)\n",
    "modelxgb = modelxgb.fit(X, y)\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(modelxgb, 'xgboost_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Los demás requerimientos de la prueba se encuentran en un script que crea y permite consumir el modelo a partir de un API creada con FastAPI.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
